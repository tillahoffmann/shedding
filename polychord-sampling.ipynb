{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools as ft\n",
    "import itertools as it\n",
    "from localscope import localscope\n",
    "import logging\n",
    "logging.basicConfig(level='WARNING')\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import pypolychord as pc\n",
    "import pypolychord.settings\n",
    "import shedding\n",
    "from scipy import stats, special\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 144\n",
    "\n",
    "args = os.environ.get('ARGS', \"-i -s 0 -l 5 -r 1 -f general workspace/test\").split()\n",
    "print(args)\n",
    "parser = argparse.ArgumentParser()\n",
    "# Positional\n",
    "parser.add_argument('parametrisation', type=shedding.Parametrisation, \n",
    "                    help='parametrisation to use')\n",
    "parser.add_argument('basedir')\n",
    "\n",
    "# Keyword\n",
    "parser.add_argument('--inflated', '-i', action='store_true', \n",
    "                    help='whether to use a zero-inflated model')\n",
    "parser.add_argument('--force', '-f', action='store_true', \n",
    "                    help='force regeneration of samples')\n",
    "parser.add_argument('--seed', '-s', type=int, help='random number generator seed')\n",
    "parser.add_argument('--nlive-factor', '-l', type=float, default=25, \n",
    "                    help='multiplicative factor for number of live points')\n",
    "parser.add_argument('--nrepeat-factor', '-r', type=float, default=5, \n",
    "                    help='multiplicative factor for number of monte carl steps')\n",
    "args = parser.parse_args(args)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and flatten some of the datasets\n",
    "datasets = shedding.load_datasets([\n",
    "    'Woelfel2020', \n",
    "    'Lui2020', \n",
    "    'Wang2020',\n",
    "    'Han2020',\n",
    "], 'publications/')\n",
    "data = shedding.flatten_datasets(datasets, loq_fill_value=-99)\n",
    "print(f'Number of patients: {data[\"num_patients\"]}')\n",
    "print(f'Number of patients with one or more positive samples: '\n",
    "      f'{(data[\"num_positives_by_patient\"] > 0).sum()}')\n",
    "print(f'Number of samples: {data[\"num_samples\"]}')\n",
    "print(f'Number of positive samples: {data[\"positive\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = shedding.Model(data['num_patients'], parametrisation=args.parametrisation, inflated=args.inflated)\n",
    "\n",
    "os.makedirs(args.basedir, exist_ok=True)\n",
    "settings = pc.settings.PolyChordSettings(model.size, 0)\n",
    "settings.base_dir = args.basedir\n",
    "settings.file_root = 'chain'\n",
    "settings.read_resume = False\n",
    "settings.feedback = 3\n",
    "settings.num_repeats = int(args.nrepeat_factor * model.size)\n",
    "settings.nlive = int(args.nlive_factor * model.size)\n",
    "settings.seed = -1 if args.seed is None else args.seed\n",
    "settings.write_resume = False\n",
    "\n",
    "filename = os.path.join(settings.base_dir, settings.file_root + '.paramnames')\n",
    "shedding.write_paramnames_file(model.parameters, filename)\n",
    "\n",
    "with open(os.path.join(args.basedir, 'model.pkl'), 'wb') as fp:\n",
    "    pickle.dump(model, fp)\n",
    "\n",
    "vars(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that we can sample and evaluate\n",
    "x = np.random.uniform(size=model.size)\n",
    "y = model.sample_params_from_vector(x)\n",
    "model.evaluate_log_likelihood_from_vector(y, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shedding.vector_to_values(model.parameters, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(settings.base_dir, settings.file_root + '.txt')\n",
    "if os.path.isfile(filename) and not args.force:\n",
    "    print(f'{filename} already exists; remove it to regenerate samples')\n",
    "else:\n",
    "    log_likelihood = ft.partial(model.evaluate_log_likelihood_from_vector, data=data)\n",
    "    with tqdm() as progress: \n",
    "        output = pc.run_polychord(log_likelihood, model.size, 0, settings, model.sample_params_from_vector, \n",
    "                                  lambda *args: progress.update())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.loadtxt(os.path.join(settings.base_dir, settings.file_root + '_equal_weights.txt'))[:, 2:]\n",
    "num_samples = len(samples)\n",
    "print(f'Obtained {num_samples} samples.')\n",
    "samples = shedding.transpose_samples(samples, model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with the right number of columns\n",
    "model_pars = [par for par, value in samples.items() if not par.endswith('_') and\n",
    "              np.ndim(value) < 2]\n",
    "nrows = ncols = len(model_pars) - 1\n",
    "fig, axes = plt.subplots(nrows, ncols, sharex='col', sharey='row',\n",
    "                         figsize=(6, 6))\n",
    "\n",
    "# Iterate over the pairs\n",
    "step = max(1, num_samples // 500)\n",
    "for i in range(len(model_pars) - 1):\n",
    "    a = model_pars[i]\n",
    "    for j in range(1, len(model_pars)):\n",
    "        ax = axes[i, j - 1]\n",
    "        if j <= i:\n",
    "            ax.set_axis_off()\n",
    "            continue\n",
    "            \n",
    "        b = model_pars[j]\n",
    "        x = samples[a][::step]\n",
    "        y = samples[b][::step]\n",
    "\n",
    "        ax.scatter(y, x, marker='.', alpha=.1)\n",
    "        if i == 0:\n",
    "            ax.set_xlabel(b, size='small')\n",
    "            ax.xaxis.set_label_position('top')\n",
    "            ax.xaxis.tick_top()\n",
    "            ax.xaxis.set_tick_params(which='both', labeltop=True)\n",
    "            \n",
    "        if j == ncols:\n",
    "            ax.set_ylabel(a, size='small')\n",
    "            ax.yaxis.set_label_position('right')\n",
    "            ax.yaxis.tick_right()\n",
    "            ax.yaxis.set_tick_params(which='both', labelright=True)\n",
    "            \n",
    "        # Draw prior bounds if they exist\n",
    "        for k, line in zip([b, a], [ax.axvline, ax.axhline]):\n",
    "            prior = model.priors.get(k)\n",
    "            if not prior:\n",
    "                continue\n",
    "            bounds = prior.bounds\n",
    "            for bound in bounds:\n",
    "                if bound is not None:\n",
    "                    line(bound, color='k', ls=':')\n",
    "            \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "for ax, key in zip((ax1, ax2), ('population', 'patient')):\n",
    "    a = f'{key}_shape'\n",
    "    b = f'{key}_scale'\n",
    "    x = samples[a]\n",
    "    y = samples[b]\n",
    "    ax.scatter(x, y, marker='.', alpha=.5)\n",
    "    ax.set_xlabel(r'Shape $q$')\n",
    "    \n",
    "    xmin = max(x.min(), y.min())\n",
    "    xmax = min(x.max(), y.max())\n",
    "    lin = np.linspace(xmin, xmax)\n",
    "    ax.plot(lin, lin, color='k', ls='--')\n",
    "    \n",
    "    ax.axvline(1, color='k', ls=':')\n",
    "    # ax.set_aspect('equal')\n",
    "    if False:\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "ax1.set_ylabel(r'Scale $\\sigma$')\n",
    "ax1.set_title('Population')\n",
    "ax2.set_title('Patient')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(samples['population_shape'], samples['population_loc'], samples['population_scale'])\n",
    "x = np.log10([shedding.gengamma_mean(q, mu, sigma) for q, mu, sigma in zipped])\n",
    "if model.inflated:\n",
    "    x += np.log10(samples['rho'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(x, density=True, alpha=.5)\n",
    "shedding.plot_kde(x, color='C0', ax=ax, label=r'population mean $\\langle y\\rangle$')\n",
    "ax.axvline(np.log10(data['load'].max()), color='k', ls=':', label=r'$\\max x$')\n",
    "ax.axvline(np.log10(data['load'][data['positive']].mean()), color='k', ls='--', \n",
    "           label=r'sample mean $\\bar x$')\n",
    "ax.set_xlabel(r'$\\log_{10}$ gene copies per mL')\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.inflated:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(samples['rho'], density=True, range=(samples['rho'].min(), 1), alpha=.5)\n",
    "    ax.axvline(np.mean(data['num_positives_by_patient'] > 0), color='k', ls='--')\n",
    "    ax.set_xlabel(r'$\\rho$')\n",
    "    fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
